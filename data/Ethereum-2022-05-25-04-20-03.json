{
    "subreddit": "Ethereum",
    "limit": 1000,
    "minimum_score": -5000,
    "sorting_options": [
        "hot",
        "top",
        "new"
    ],
    "posts": [
        {
            "id": "ux29xt",
            "title": "useless instructions in optimized EVM bytecode?",
            "url": "https://i.redd.it/7acfjg6lvh191.png",
            "author": "yarb3d",
            "created_utc": 1653429716.0,
            "score": 12,
            "num_comments": 6,
            "subreddit": "ethereum",
            "selftext": "",
            "stickied": false,
            "comments": [
                {
                    "id": "i9wjook",
                    "author": "smi2ler",
                    "score": 5,
                    "created_utc": 1653458150.0,
                    "response": "You might want to try r/ethdev",
                    "depth": 1,
                    "comments": [
                        {
                            "id": "i9x6dbw",
                            "author": "yarb3d",
                            "score": 1,
                            "created_utc": 1653477028.0,
                            "response": "Thanks!  I didn't know about that sub, so your pointer is very helpful.",
                            "depth": 2,
                            "comments": []
                        }
                    ]
                },
                {
                    "id": "i9uzwky",
                    "author": "yarb3d",
                    "score": 5,
                    "created_utc": 1653429777.0,
                    "response": "Some naive questions from someone not all that experienced with EVM.  I'm trying to understand the EVM bytecode generated by solc.    \nThe picture above shows (the control flow graph of) the runtime bytecode obtained using the command `solc --optimize --overwrite --bin-runtime -o. mypgm.sol`; the source code for the program is in the top left corner.  There are a couple of things here that I don't understand.  \n1) The function `dummy_fn()` in the library `DummyMath` is used only in the constructor, which is called only when the contract is created.  But from the occurrence of the constant `0x98765` (shown highlighted in both the source code and the bytecode) it looks like bytecode for `dummy_fn()` is being inserted into the runtime bytecode as well.  As far as I can tell there is no way to access the instructions for this function.  Why is it being added into the runtime bytecode?  \n2) What is the function of the code in basic block at 0x5a ?  \nMany thanks.",
                    "depth": 1,
                    "comments": [
                        {
                            "id": "i9wt9g0",
                            "author": "TheRealFloomby",
                            "score": 2,
                            "created_utc": 1653465939.0,
                            "response": "1. So when the constructor runs xyz starts with the value of zero because this is the default value for a uint. The constructor calls dummy_fn() and multiplies this by the 0x98765 constant. The optimizer does not optimize away library code like this. It could break things in some situations.\n\n\n2. The code in block 0x5a is the code that checks the bounds on the multiplication to make sure there was not an overflow error. (notice the revert opcode on the left side of the branch.) Wrap the multiplication in an unchecked block and it should go away.",
                            "depth": 2,
                            "comments": []
                        }
                    ]
                }
            ]
        }
    ]
}
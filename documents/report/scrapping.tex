We used the official Reddit API for the scraping part of our project. To facilitate our work, we used the PRAW (Python Reddit API Wrapper) library.

Our bot runs on a linux server and checks all 20 minutes for new posts on specific subreddits. For this project, we used the following list of subreddits: Bitcoin, Ethereum, Dogecoin, BitcoinBeginners, CryptoCurrencies, CryptoTechnology, CryptoMarkets, Binance, CoinBase, btc.
Using the multiprocessing package of python, we spawn a process for each subreddit for the scraping to happen in parallel.
Also, since we care about actual and real time data, we consider the following sorting options provided by the Reddit API: hot posts, top posts and new posts. We don't set some time bound on when the post has been published, since we store the timestamps of each post and comment and filter what we need. This works really well and we didnt encounter any API limitations.

Everytime a new scraping run is started, we create a new JSON file with the timestsamp of the start of the scraping. All new posts that will be found in this run, will be stored inside the newly created JSON file. As time goes by, a post might receive many new comments. Therefore, if a previously crawled post has an increase in comments of more than 30\%, we also refetch that post and update the JSON file it was originally stored in. 